{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#003d5c>Árboles de Decisión</font>\n",
    "\n",
    "\n",
    "Es un algoritmo que proporciona una arquitectura condicional de varios niveles para el análisis predictivo mediante la evaluación de la ganancia de información incremental.\n",
    "\n",
    "<img src=\"images/groot.gif\"></img>\n",
    "\n",
    "Piense en el árbol de decisión como un un árbol lleno de condiciones `if-else`. La condición más eficiente se encuentra en la parte superior y disminuye gradualmente a medida que descendemos (en la mayoría de los casos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#003d5c>**¿Por qué aprenderemos Árboles de Decisión?**</font>\n",
    "\n",
    "- Puede aplicarse a problemas de regresión y clasificación\n",
    "- Tienen muchas propiedades útiles\n",
    "- Son muy populares\n",
    "- Son la base de modelos más complejos\n",
    "- Tienen una forma diferente de \"pensar\" que los otros modelos que hemos estudiado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>Objetivos de la lección</font>\n",
    "\n",
    "Los estudiantes podrán:\n",
    "\n",
    "- Explicar cómo se crea un árbol de decisión\n",
    "- Construir un modelo de árbol de decisión en scikit-learn\n",
    "- Tunear un modelo de árbol de decisión y  explicar cómo el tuning impacta al modelo.\n",
    "- Interpretar un diagrama de árbol\n",
    "- Describir las diferencias principales entre los árboles de regresión y clasificación\n",
    "- Decida si un árbol de decisión es un modelo apropiado para un problema dado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta parte teórica se puede revisar en el octavo capítulo del libro [**Introduction to Statistical Learning**](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('qDcl-FRnwSU', width=1000,height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#003d5c>1. Árboles de Regresión</font>\n",
    "\n",
    "Datos de un jugador de Grandes Ligas de 1986-87::\n",
    "\n",
    "- **Años** (eje x): número de años jugando en las ligas mayores\n",
    "- **Hits** (eje y): número de hits en el año anterior\n",
    "- **Salario** (color): el salario bajo es azul / verde, el salario alto es rojo / amarillo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Salary data](https://github.com/justmarkham/DAT8/raw/226791169b1cc6df8e8845c12e34e748d5ffaa85/notebooks/images/salary_color.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio grupal:**\n",
    "\n",
    "- Los datos anteriores son nuestros **datos de entrenamiento**.\n",
    "- Queremos construir un modelo que prediga el salario de **futuros jugadores** basado en años y Hits.\n",
    "- Vamos a \"segmentar\" el grupo de características en regiones, y luego usar el **salario medio en cada región** como el salario previsto para los futuros jugadores.\n",
    "- Se quiere **maximizar** la similitud (u \"homogeneidad\") dentro de una región determinada, y **minimizar** la similitud entre diferentes regiones.\n",
    "\n",
    "\n",
    "**Reglas para segmentar:**\n",
    "\n",
    "- Solo puedes usar **líneas rectas**, dibujadas una a la vez.\n",
    "- Estas líneas deben ser verticales u horizontales.\n",
    "- Una línea **se detiene** cuando golpea una línea existente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Salary regions](https://github.com/justmarkham/DAT8/raw/226791169b1cc6df8e8845c12e34e748d5ffaa85/notebooks/images/salary_regions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arriba están las regiones creadas por una computadora::\n",
    "\n",
    "- $R_1$: jugadores con **menos de 5 años** de experiencia, salario medio de **\\$166,000**\n",
    "- $R_2$: jugadores con **5 o más años** de experiencia y **menos de 118 visitas**, salario medio de **\\$403,000**\n",
    "- $R_3$: jugadores con **5 o más años** de experiencia y **118 hits o más**, Salario medio de **\\$846,000**\n",
    "\n",
    "**Nota:** Años y Hits son enteros, pero la convención es usar el **punto medio** entre valores adyacentes para etiquetar una división.\n",
    "\n",
    "Estas regiones se usan para hacer predicciones sobre **datos fuera de la muestra**. ¡Por lo tanto, solo hay tres predicciones posibles! (¿Es esto diferente de cómo **la regresión lineal** hace predicciones?)\n",
    "\n",
    "A continuación se muestra el árbol de regresión equivalente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Salary tree](https://github.com/justmarkham/DAT8/raw/226791169b1cc6df8e8845c12e34e748d5ffaa85/notebooks/images/salary_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera división es **Años <4.5**, por lo que esa división va en la parte superior del árbol. Cuando una regla de división es **Verdadero**, sigue la rama izquierda. Cuando una regla de división es **Falsa**, sigue la rama derecha.\n",
    "\n",
    "Para los jugadores en la **rama izquierda**, el Salario medio es \\$166,000, por lo que se etiqueta con ese valor. (El salario se ha dividido por 1000 y se ha transformado a 5.11 usando el logaritmo).\n",
    "\n",
    "Para jugadores en la **rama derecha**, hay una división adicional en **Hits <117.5**, dividiendo jugadores en dos regiones Salario más: \\$403,000 (transformado a 6.00), y \\$846,000 (transformado a 6.74)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Salary tree annotated](https://github.com/justmarkham/DAT8/raw/226791169b1cc6df8e8845c12e34e748d5ffaa85/notebooks/images/salary_tree_annotated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué le dice este árbol acerca de sus datos?¿Qué insights puedes obtener?**\n",
    "\n",
    "- Años es el factor más importante que determina el Salario, con un menor número de años correspondientes a un Salario inferior.\n",
    "- Para un jugador con un número menor de años, Hits no es un factor importante que determina el salario.\n",
    "- Para un jugador con un mayor número de años, Hits es un factor importante que determina el salario, con un mayor número de Hits correspondientes a un salario más alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta del Millón:** ¿Qué le gusta y qué le desagrada de los árboles de decisión hasta el momento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>I. Construir un árbol de regresión a mano</font>\n",
    "\n",
    "Los **datos de entrenamiento** están en un pequeño dataset de [precios de venta de vehículos usados](https://raw.githubusercontent.com/justmarkham/DAT8/master/data/vehicles_train.csv). Su meta es **predecir el precio** para los datos de prueba.\n",
    "\n",
    "1. Lea los datos en un DataFrame.\n",
    "2. Explore los datos por medio de gráficas, o agrupaciones (recordar el uso del `group_by`).\n",
    "3. Decida qué característica es el predictor más importante y utilícela para crear su primera regla de división.\n",
    "    - Solo se permiten divisiones binarias.\n",
    "4. Después de hacer su primera división, divida su DataFrame en dos partes y luego explore cada parte para descubrir qué otras divisiones hacer.\n",
    "5. Deje de hacer divisiones una vez que esté convencido de que logra un buen equilibrio entre el ajuste insuficiente (underfitting) y el ajuste excesivo (overfitting).\n",
    "    - Tu objetivo es construir un modelo que generalice bien.\n",
    "    - ¡Puedes dividir la misma variable varias veces!\n",
    "6. Dibuje su árbol, etiquetando las hojas con el precio promedio de las observaciones en esa región.\n",
    "    - Asegúrate de que nada esté al revés: sigue la **rama izquierda** si la regla es verdadera, y la **rama derecha** si la regla es falsa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>¿Cómo construye una computadora un árbol de regresión?</font>\n",
    "\n",
    "**Enfoque ideal:** Considera cada posible partición del grupo de características (no factible computacionalmente)\n",
    "\n",
    "**Enfoque \"suficientemente bueno\":** división binaria recursiva\n",
    "\n",
    "1. Comienza en la parte superior del árbol\n",
    "2. Para **cada característica**, examina **todos los puntos de corte posibles**, y elige la característica y el punto de corte para que el árbol resultante tenga el error cuadrático medio (MSE) más bajo posible.\n",
    "3. Examina las dos regiones resultantes, y nuevamente haga una **división simple** (en una de las regiones) para minimizar el MSE.\n",
    "4. Continúa repitiendo el paso 3 hasta que se cumpla un **criterio de detención**:\n",
    "    - profundidad máxima del árbol (número máximo de divisiones requeridas para llegar a una hoja)\n",
    "    - número mínimo de observaciones en una hoja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=#003d5c>Aplicación de la lógica: Elegir el punto de corte ideal para una característica dada</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'data/vehicles_train.csv'\n",
    "train = pd.read_csv(url, encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"vtype\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Codificar \"car\" como 0 y \"truck\" como 1\n",
    "train['vtype'] = train.vtype.map({'car':0, 'truck':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Antes de hacer las divisiones, calculemos la media de todo el dataset para que sea nuestra valor de predicción\n",
    "train['prediction_sin_reglas'] = train.price.mean()\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#003d5c>Calcular el error (MSE):</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(((train['price'] - train['prediction_sin_reglas'])**2).mean()) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#003d5c>a) Elegir nuestra primera mejor división:</font>**\n",
    "<br><br>\n",
    "Por ejemplo dividamos todo el dataset por la variable `year` y el valor de `2010` y calculemos los promedios del precio en las 2 regiones obtenidas y asignarles como valor de predicción en la variable `pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.loc[train.year < year, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.year >= year, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[train.year < year, 'pred_año_2010'] = train.loc[train.year < year, 'price'].mean()\n",
    "train.loc[train.year >=year, 'pred_año_2010'] = train.loc[train.year >=year, 'price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(((train['price'] - train['pred_año_2010'])**2).mean()) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=#003d5c>Región de la Izquierda:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_izq = train.loc[train.year<2010].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_izq.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#003d5c>Región de la Derecha:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_der = train.loc[train.year>=2010].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_der.year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos una función que nos permite calcular el error obtenido por la división en 2 regiones en base a un valor de la variable `year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_año(train, year):\n",
    "    train.loc[train.year <year, 'pred'] = train.loc[train.year <year, 'price'].mean()\n",
    "    train.loc[train.year>=year, 'pred'] = train.loc[train.year>=year, 'price'].mean()\n",
    "    return((((train['price'] - train['pred'])**2).mean()) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_min = float('inf')\n",
    "year_split = 0\n",
    "for year in train.year.unique():\n",
    "    error_año_var = error_año(train, year)\n",
    "    print(year, \": \", error_año_var)\n",
    "    if error_año_var < error_min:\n",
    "        error_min = error_año_var\n",
    "        year_split = year\n",
    "print(\"Se debe hacer la división por el valor de \", year_split, \"ya que genera 2 regiones que nos permiten obtener un error de \", error_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#003d5c>b) Evaluar el punto de corte con el MSE más bajo:</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Pero es correcto que hayamos elegido la variable `year`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_split(train, var, value):\n",
    "    train.loc[train[var] <value, 'pred'] = train.loc[train[var] <value, 'price'].mean()\n",
    "    train.loc[train[var]>=value, 'pred'] = train.loc[train[var]>=value, 'price'].mean()\n",
    "    return ((((train['price'] - train['pred'])**2).mean()) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_min, var_final, val_final = float('inf'), '', 0\n",
    "for var_ in ['year', 'miles', 'doors', 'vtype']:\n",
    "    print('-------------{}-------------'.format(var_))\n",
    "    for val_ in train[var_].unique():\n",
    "        error = error_split(train, var_, val_)\n",
    "        print(val_, \": \", error)\n",
    "        if error < error_min:\n",
    "            error_min = error\n",
    "            var_final, val_final = var_, val_\n",
    "print(\"\\n--------------------------------------------------\")\n",
    "print(\"Se debe hacer la división por el valor de \", val_final, \" de la variable \", var_final, \" ya que genera 2 regiones que nos permiten obtener un error de \", error_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10, 4)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la variable 'year' (eje-X) versus RMSE (eje-y)\n",
    "values = train['year'].unique()\n",
    "errors = [error_split(train, 'year', v) for v in values]\n",
    "plt.plot(values, errors)\n",
    "plt.xlabel('Punto de corte en \"year\"')\n",
    "plt.ylabel('RMSE (más pequeño es mejor)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#003d5c>c) Examina las 2 regiones resultantes:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_izq = train.loc[train['year'] <2007, :]\n",
    "train_der = train.loc[train['year']>=2007, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_izq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#003d5c>d) Evaluar si se cumple criterio de detención:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_izq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_der.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#003d5c>Continuar el Ciclo:</font>**\n",
    "<br><br>Con la región de la Izquierda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_min, var_final, val_final = float('inf'), '', 0\n",
    "for var_ in ['year', 'miles', 'doors', 'vtype']:\n",
    "    print('-------------{}-------------'.format(var_))\n",
    "    for val_ in train_izq[var_].unique():\n",
    "        error = error_split(train_izq, var_, val_)\n",
    "        print(val_, \": \", error)\n",
    "        if error < error_min:\n",
    "            error_min = error\n",
    "            var_final, val_final = var_, val_\n",
    "print(\"\\n--------------------------------------------------\")\n",
    "print(\"Se debe hacer la división por el valor de \", val_final, \" de la variable \", var_final, \" ya que genera 2 regiones que nos permiten obtener un error de \", error_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_izq_izq = train_izq.loc[train_izq['miles']< 138000]\n",
    "train_izq_der = train_izq.loc[train_izq['miles']>=138000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_izq_izq.shape)\n",
    "print(train_izq_der.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la región de la Derecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_min, var_final, val_final = float('inf'), '', 0\n",
    "for var_ in ['year', 'miles', 'doors', 'vtype']:\n",
    "    print('-------------{}-------------'.format(var_))\n",
    "    for val_ in train_der[var_].unique():\n",
    "        error = error_split(train_der, var_, val_)\n",
    "        print(val_, \": \", error)\n",
    "        if error < error_min:\n",
    "            error_min = error\n",
    "            var_final, val_final = var_, val_\n",
    "print(\"\\n--------------------------------------------------\")\n",
    "print(\"Se debe hacer la división por el valor de \", val_final, \" de la variable \", var_final, \" ya que genera 2 regiones que nos permiten obtener un error de \", error_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_der_izq = train_der.loc[train_der['year']< 2012]\n",
    "train_der_der = train_der.loc[train_der['year']>=2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_der_izq.shape)\n",
    "print(train_der_der.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_der_izq = train_der.loc[train_der['miles']< 30000]\n",
    "train_der_der = train_der.loc[train_der['miles']>=30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_der_izq.shape)\n",
    "print(train_der_der.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "  <strong>Recordar:</strong> Antes de cada división, este proceso se repite para cada característica, y se eligen la característica y el punto de corte que produce la `RMSE` más baja.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>II. Construyendo un árbol de regresión en scikit-learn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir nuestro dataset de Entrenamiento y el Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictores = ['year', 'miles', 'doors', 'vtype']\n",
    "X = train[predictores]\n",
    "y = train.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar un objeto de la clase DecisionTreeRegressor (con random_state=1)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "treereg = DecisionTreeRegressor(random_state=1, max_depth=2, criterion='mse')\n",
    "treereg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "treereg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar el Árbol de Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graph = Source( export_graphviz(treereg, out_file=None, feature_names=predictores, filled=True))\n",
    "#SVG(graph.pipe(format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leyendo los nodos internos:\n",
    "\n",
    "- **samples:** cantidad de observaciones en ese nodo antes de dividir\n",
    "- **mse:** MSE calculado al comparar los valores de respuesta reales en ese nodo con el valor de respuesta promedio en ese nodo\n",
    "- **regla:** regla utilizada para dividir ese nodo (ir a la izquierda si es verdadero, ir a la derecha si es falso)\n",
    "\n",
    "Leyendo las hojas:\n",
    "\n",
    "- **samples:** cantidad de observaciones en ese nodo\n",
    "- **value:** valor de respuesta promedio en ese nodo\n",
    "- **mse:** MSE calculado al comparar los valores de respuesta reales en ese nodo contra \"value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>III. Tunning en un árbol de regresión usando scikit-learn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Usando  for\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "for max_depth in range(1, 9):\n",
    "    treereg = DecisionTreeRegressor(random_state=1, max_depth=max_depth, criterion='mse')\n",
    "    treereg.fit(X, y)\n",
    "    error = np.sqrt(mean_squared_error(y, treereg.predict(X)))\n",
    "    error_list.append(error)\n",
    "    print('max_depth={}, error={}'.format(max_depth, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la variable 'year' (eje-X) versus RMSE (eje-y)\n",
    "values = range(1, 9)\n",
    "plt.plot(values, error_list)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('RMSE (más pequeño es mejor)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "treereg = DecisionTreeRegressor(random_state=1, max_depth=max_depth, criterion='mse')\n",
    "parameters = {'max_depth': list(range(1, 9))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(treereg, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(treereg, X, y, cv=14, scoring='neg_mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>¿Qué sucede cuando generamos un árbol demasiado profundo?</font>\n",
    "\n",
    "- Izquierda: Árbol de regresión para Salario **crecimiento más profundo**\n",
    "- Derecha: Comparación de **errores de entrenamiento, prueba y validación cruzada** para árboles con diferentes números de hojas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Salary tree grown deep](https://github.com/justmarkham/DAT8/raw/226791169b1cc6df8e8845c12e34e748d5ffaa85/notebooks/images/salary_tree_deep.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **error de entrenamiento** continúa disminuyendo a medida que aumenta el tamaño del árbol (debido al sobreajuste), pero el error **de validación cruzada** más bajo ocurre para un árbol con 3 hojas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning: Ajustando un árbol de regresión\n",
    "\n",
    "Tratemos de reducir el RMSE ajustando el parámetro **max_depth**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba diferentes valores uno a uno\n",
    "treereg = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "scores = cross_val_score(treereg, X, y, cv=14, scoring='neg_mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O bien, podríamos hacer un bucle para probar un rango de valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lista de valores para probar\n",
    "max_depth_range = range(1, 8)\n",
    "\n",
    "# lista para almacenar el RMSE promedio para cada valor de max_depth\n",
    "RMSE_scores = []\n",
    "\n",
    "# use LOOCV con cada valor de max_depth\n",
    "for depth in max_depth_range:\n",
    "    treereg = DecisionTreeRegressor(max_depth=depth, random_state=1)\n",
    "    MSE_scores = cross_val_score(treereg, X, y, cv=14, scoring='neg_mean_squared_error')\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plot max_depth (x-axis) versus RMSE (y-axis)\n",
    "plt.plot(max_depth_range, RMSE_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth = 3 fue el mejor, así que ajuste un árbol usando ese parámetro\n",
    "treereg = DecisionTreeRegressor(max_depth=3, random_state=1)\n",
    "treereg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Importancia de Gini\" de cada característica: la reducción total de errores (normalizada) provocada por esa característica\n",
    "pd.DataFrame({'feature':predictores, 'importance':treereg.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer predicciones para los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer la data de prueba\n",
    "url = 'data/vehicles_test.csv'\n",
    "test = pd.read_csv(url, encoding=\"latin1\")\n",
    "test['vtype'] = test.vtype.map({'car':0, 'truck':1})\n",
    "test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta: ** Usando el diagrama de árbol de arriba, ¿qué predicciones hará el modelo para cada observación?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizar el modelo ajustado para hacer predicciones sobre los datos de prueba\n",
    "X_test = test[predictores]\n",
    "y_test = test.price\n",
    "y_pred = treereg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular RMSE\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#003d5c>2. Árboles de clasificación</font>\n",
    "Una pequeña Introducción en la siguiente página: <a href=\"http://www.r2d3.us/una-introduccion-visual-al-machine-learning-1/\">http://www.r2d3.us/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de árboles de regresión y árboles de clasificación\n",
    "\n",
    "|Árbol de regresión|Árbol de clasificación|\n",
    "|---|---|\n",
    "|Predice una respuesta continua|Predice una respuesta categórica|\n",
    "|Predice usando la respuesta media de cada hoja|Predice usando la clase más común en cada hoja|\n",
    "|Las divisiones se eligen para minimizar MSE|Las divisiones se eligen para minimizar el índice de Gini (discutido a continuación)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterios de división para los árboles de clasificación\n",
    "\n",
    "Opciones comunes para los criterios de división:\n",
    "\n",
    "- **Tasa de error de clasificación:** fracción de observaciones de entrenamiento en una región que no pertenece a la clase más común\n",
    "- **Índice de Gini:** medida de la varianza total entre clases en una región\n",
    "- **Entropía:** medida del desorden. La entropía es un indicador de lo desordenado que son tus datos.\n",
    "<img src=\"https://sebastianraschka.com/images/faq/decision-tree-binary/overview-plot.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de tasa de error de clasificación\n",
    "\n",
    "Imagina que estamos prediciendo si alguien compra un iPhone o un Android:\n",
    "\n",
    "- En un nodo en particular, hay **25 observaciones** (compradores de teléfonos), de los cuales **10 compraron iPhones y 15 compraron Android**.\n",
    "- Dado que la clase mayoritaria es **Android**, esa es nuestra predicción para las 25 observaciones, y por lo tanto la tasa de error de clasificación es **10/25 = 40%**.\n",
    "\n",
    "Nuestro objetivo al hacer splits es **reducir la tasa de error de clasificación**. Probemos dividir en género:\n",
    "\n",
    "- **Hombres:** 2 iPhones y 12 Androids, por lo tanto, la clase predicha es Android. (2 equivocaciones)\n",
    "- **Mujeres:** 8 iPhones y 3 Androids, por lo que la clase prevista es iPhone. (3 equivocaciones)\n",
    "- Tasa de error de clasificación después de esta división sería **5/25 = 20%**\n",
    "\n",
    "Compare eso con una división en la edad:\n",
    "\n",
    "- **30 o menos:** 4 iPhones y 8 Androids, por lo tanto, la clase predicha es Android. (4 equivocaciones)\n",
    "- **31 o más:** 6 iPhones y 7 Androids, por lo tanto, la clase predicha es Android. (6 equivocaciones)\n",
    "- Tasa de error de clasificación después de esta división sería **10/25 = 40%**\n",
    "\n",
    "El algoritmo del árbol de decisión intentará **cada división posible en todas las características**, y elegirá la división que más **reduzca la tasa de error.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de Índice de Gini\n",
    "\n",
    "Calcule el índice de Gini antes de hacer una división:\n",
    "\n",
    "$$1 - \\left(\\frac {iPhone} {Total}\\right)^2 - \\left(\\frac {Android} {Total}\\right)^2 = 1 - \\left(\\frac {10} {25}\\right)^2 - \\left(\\frac {15} {25}\\right)^2 = 0.48$$\n",
    "\n",
    "- El **valor máximo** del índice de Gini es 0.5, y ocurre cuando las clases están perfectamente balanceadas en un nodo.\n",
    "- El **valor mínimo** del índice de Gini es 0, y ocurre cuando solo hay una clase representada en un nodo.\n",
    "- Se dice que un nodo con **un índice de Gini más bajo es más \"puro\"**.\n",
    "\n",
    "Evaluar la división en ** sexo ** usando el índice de Gini:\n",
    "\n",
    "$$\\text{Hombres: } 1 - \\left(\\frac {2} {14}\\right)^2 - \\left(\\frac {12} {14}\\right)^2 = 0.24$$\n",
    "$$\\text{Mujeres: } 1 - \\left(\\frac {8} {11}\\right)^2 - \\left(\\frac {3} {11}\\right)^2 = 0.40$$\n",
    "$$\\text{Peso Promedio: } 0.24 \\left(\\frac {14} {25}\\right) + 0.40 \\left(\\frac {11} {25}\\right) = 0.31$$\n",
    "\n",
    "Evaluar la división en **edad** usando el índice de Gini:\n",
    "\n",
    "$$\\text{30 o joven: } 1 - \\left(\\frac {4} {12}\\right)^2 - \\left(\\frac {8} {12}\\right)^2 = 0.44$$\n",
    "$$\\text{31 o viejo: } 1 - \\left(\\frac {6} {13}\\right)^2 - \\left(\\frac {7} {13}\\right)^2 = 0.50$$\n",
    "$$\\text{Peso Promedio: } 0.44 \\left(\\frac {12} {25}\\right) + 0.50 \\left(\\frac {13} {25}\\right) = 0.47$$\n",
    "\n",
    "De nuevo, el algoritmo del árbol de decisiones intentará **cada posible división**, y elegirá la división que **reduce el índice de Gini (y así aumenta la \"pureza del nodo\") más.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando la tasa de error de clasificación y el índice de Gini\n",
    "\n",
    "- Generalmente se prefiere el índice de Gini porque hará divisiones que **aumentan la pureza del nodo**, incluso si esa división no cambia la tasa de error de clasificación.\n",
    "- La pureza del nodo es importante porque nos interesan las **proporciones de clase** en cada región, ya que así es como calculamos la **probabilidad pronosticada** de cada clase.\n",
    "- Los criterios de división predeterminados de scikit-learn para los árboles de clasificación son el índice de Gini.\n",
    "\n",
    "Nota: Hay otro criterio de división común llamado **entropía cruzada**. Es numéricamente similar al índice de Gini, pero más lento de calcular, por lo tanto, no es tan popular como el índice de Gini. Queda como tarea revisarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo un árbol de clasificación en scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construiremos un árbol de clasificación usando el dataset de Crédito Hipotecario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lectura del dataset\n",
    "df = pd.read_csv('data/DS_Credito Hipotecario.csv')\n",
    "\n",
    "# Preprocesamiento de la data\n",
    "df['SEXO'].fillna(df['SEXO'].mode()[0], inplace=True)\n",
    "df['FLAG_CASADO'].fillna(df['FLAG_CASADO'].mode()[0], inplace=True)\n",
    "df['NRO_DEPENDIENTES'].fillna(df['NRO_DEPENDIENTES'].mode()[0], inplace=True)\n",
    "df['FLAG_TRAB_INDEP'].fillna(df['FLAG_TRAB_INDEP'].mode()[0], inplace=True)\n",
    "df['INGRESOS_COSOLICITANTE'].fillna(df['INGRESOS_COSOLICITANTE'].mean(), inplace=True)\n",
    "df['MONTO_PRESTAMO_MILES'].fillna(df['MONTO_PRESTAMO_MILES'].mean(), inplace=True)\n",
    "df['PLAZO_PRESTAMO_MESES'].fillna(df['PLAZO_PRESTAMO_MESES'].mean(), inplace=True)\n",
    "df['FLAG_HISTORIAL_CREDITICIO'].fillna(df['FLAG_HISTORIAL_CREDITICIO'].mode()[0], inplace=True)\n",
    "\n",
    "df['SEXO'] = df['SEXO'].map({'Male': 0, 'Female': 1})\n",
    "df['FLAG_CASADO'] = df['FLAG_CASADO'].map({'No': 0, 'Yes': 1})\n",
    "df['EDUCACION'] = df['EDUCACION'].map({'Not Graduate': 0, 'Graduate': 1})\n",
    "df['FLAG_TRAB_INDEP'] = df['FLAG_TRAB_INDEP'].map({'No': 0, 'Yes': 1})\n",
    "df['FLAG_HISTORIAL_CREDITICIO'] = df['FLAG_HISTORIAL_CREDITICIO'].map({'Malo': 0, 'Bueno': 1})\n",
    "df = pd.concat([df, pd.get_dummies(df['TIPO_ZONA'], prefix = 'TIPO_ZONA', drop_first = True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['NRO_DEPENDIENTES'], prefix = 'NRO_DEPENDIENTES', drop_first = True)], axis=1)\n",
    "del df['TIPO_ZONA']\n",
    "del df['NRO_DEPENDIENTES']\n",
    "df['FLAG_CRED_HIPO'] = df['FLAG_CRED_HIPO'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **FLAG_CRED_HIPO:** 0=No al CH, 1=Sí al CH (Target)\n",
    "- **EDUCACION:** 0=No Graduado, 1=Graduado\n",
    "    - ¿Qué pasará si el árbol se divide en esta característica?\n",
    "- **SEXO:** 0=hombre, 1=mujer\n",
    "- **INGRESOS_SOLICITANTE:** valor numérico\n",
    "- **FLAG_HISTORIAL_CREDITICIO:** Bueno o Malo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definir X e Y\n",
    "predictores = ['SEXO', 'FLAG_CASADO', 'EDUCACION', 'FLAG_TRAB_INDEP', 'INGRESOS_SOLICITANTE', 'INGRESOS_COSOLICITANTE',\n",
    "                'MONTO_PRESTAMO_MILES', 'PLAZO_PRESTAMO_MESES','FLAG_HISTORIAL_CREDITICIO', 'TIPO_ZONA_Semiurban',\n",
    "                'TIPO_ZONA_Urban', 'NRO_DEPENDIENTES_1', 'NRO_DEPENDIENTES_2','NRO_DEPENDIENTES_3+']\n",
    "X = df[predictores]\n",
    "y = df.FLAG_CRED_HIPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar un árbol de decisión con max_depth=3 con todos los datos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclf = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "treeclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder visualizar la estructura del árbol necesitan tener instalado lo siguiente:\n",
    "\n",
    "Librería de Python Graphviz. Ejecutar **pip install graphviz** en la ventana de línea de comandos. <br>\n",
    "Software Graphviz (Graph Visualization). Lo pueden descargar desde este enlace: [LINK](https://graphviz.gitlab.io/_pages/Download/Download_windows.html)<br>\n",
    "**Nota**: Recordar que deben referenciarla en variables de entorno. Es decir, copiar ruta \"C:\\Program Files (x86)\\Graphviz2.38\\bin\" (verificar que esta ruta exista en su portátil después de la instalación) en la variable de entorno del sistema \"Path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graph = Source(export_graphviz(treeclf, out_file=None, feature_names=predictores, filled=True))\n",
    "#SVG(graph.pipe(format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from IPython.display import display                               \n",
    "from ipywidgets import interactive\n",
    "\n",
    "def plot_tree(crit, split, depth, min_split, min_leaf=0.2):\n",
    "    estimator = DecisionTreeClassifier(random_state = 0 \n",
    "          , criterion = crit\n",
    "          , splitter = split\n",
    "          , max_depth = depth\n",
    "          , min_samples_split=min_split\n",
    "          , min_samples_leaf=min_leaf)\n",
    "    estimator.fit(X, y)\n",
    "    graph = Source(export_graphviz(estimator\n",
    "          , out_file=None\n",
    "          , feature_names=predictores\n",
    "          , class_names=['0', '1', '2']\n",
    "          , filled = True))\n",
    "\n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"inter=interactive(plot_tree \n",
    "   , crit = [\"gini\", \"entropy\"]\n",
    "   , split = [\"best\", \"random\"]\n",
    "   , depth=[1,2,3,4]\n",
    "   , min_split=(0.1,1)\n",
    "   , min_leaf=(0.1,0.5))\n",
    "display(inter)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribución del Target en el primer nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('FLAG_CRED_HIPO').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculo de Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini = 1 - (192.0/614)**2 - (422/614)**2\n",
    "round(gini, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Región de la Izquierda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_izq = df.loc[df['FLAG_HISTORIAL_CREDITICIO'] <= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_izq.groupby('FLAG_CRED_HIPO').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_izq = 1 - (82.0/89)**2 - (7.0/89)**2\n",
    "round(gini_izq, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Región de la Derecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_der = df.loc[df['FLAG_HISTORIAL_CREDITICIO'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_der.groupby('FLAG_CRED_HIPO').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_der = 1 - (110.0/525)**2 - (415.0/525)**2\n",
    "round(gini_der, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_2nd_nivel = gini_izq * (89/ 614) + gini_der * (525/ 614)\n",
    "gini_2nd_nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Por qué Gini y no Error de Clasificación?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/decisionTreeMissClassification.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe la división en esta parte del árbol: la **misma clase** se predice en sus dos hojas. Esa división no afectó la **tasa de error de clasificación**, aunque aumentó la **pureza del nodo**, que es importante porque aumenta la precisión de nuestras probabilidades predichas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculando la importancia de variables\n",
    "pd.DataFrame({'feature':predictores, 'importance':treeclf.feature_importances_}).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_accuracy_list, train_auc_list = [], []\n",
    "test_accuracy_list, test_auc_list = [], []\n",
    "max_depth_range = list(range(1, 30))\n",
    "for max_depth in max_depth_range:\n",
    "    \n",
    "    treeclf = DecisionTreeClassifier(max_depth=max_depth, random_state=1)\n",
    "    treeclf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = treeclf.predict(X_train)\n",
    "    y_test_pred = treeclf.predict(X_test)\n",
    "    \n",
    "    y_train_pred_proba = treeclf.predict_proba(X_train)[:, 1]\n",
    "    y_test_pred_proba = treeclf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    auc_train = roc_auc_score(y_train, y_train_pred_proba)\n",
    "    \n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    auc_test = roc_auc_score(y_test, y_test_pred_proba)\n",
    "    \n",
    "    train_accuracy_list.append(accuracy_train)\n",
    "    train_auc_list.append(auc_train)\n",
    "    test_accuracy_list.append(accuracy_test)\n",
    "    test_auc_list.append(auc_test)\n",
    "    \n",
    "    print(\"Train - max_depth: {}, accuracy: {}, auc: {}\".format(max_depth, accuracy_train, auc_train))\n",
    "    print(\"Test - max_depth: {}, accuracy: {}, auc: {} \\n\".format(max_depth, accuracy_test, auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "ax[0].plot(max_depth_range, train_accuracy_list, c='orange')\n",
    "ax[0].plot(max_depth_range, test_accuracy_list,  c='skyblue')\n",
    "ax[1].plot(max_depth_range, train_auc_list, c='orange')\n",
    "ax[1].plot(max_depth_range, test_auc_list,  c='skyblue')\n",
    "ax[0].set_title('Accuracy evaluation')\n",
    "ax[0].set_xlabel('max_depth')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[1].set_title('AUC Score evaluation')\n",
    "ax[1].set_xlabel('max_depth')\n",
    "ax[1].set_ylabel('AUC Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>Aplicar al Dataset de Attrition</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cargamos nuestra data de Attrition\n",
    "df_train_clientes = pd.read_excel('data/train_clientes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clientes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seleccionamos las variables de  tipo \"objeto\"\n",
    "columns_cat = df_train_clientes.select_dtypes(include=['object']).columns\n",
    "labelEncoders = {}\n",
    "\n",
    "# Hacemos el Label Encoding\n",
    "for col in columns_cat:\n",
    "    labelEncoders[col] = LabelEncoder()\n",
    "    df_train_clientes['{0}_ENC'.format(col)] = labelEncoders[col].fit_transform(df_train_clientes[col].fillna('na'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Eliminamos las variables del tipo object\n",
    "df_train_clientes.drop(axis=1, labels=columns_cat, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para reducir la memoria que ocupa un DataFrame\n",
    "def optimizar(df):\n",
    "    float_cols = df.select_dtypes(include=['float'])\n",
    "    int_cols = df.select_dtypes(include=['integer'])\n",
    "\n",
    "    for var_f in float_cols.columns:\n",
    "        df[var_f] = pd.to_numeric(df[var_f], downcast='float')\n",
    "    for var_i in int_cols.columns:\n",
    "        df[var_i] = pd.to_numeric(df[var_i], downcast='integer')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizamos la memoria del DataFrame\n",
    "df_train_clientes = optimizar(df_train_clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definir los predictores (variables independientes)\n",
    "predictores = [c for c in df_train_clientes.columns if c not in [\"ID_CORRELATIVO\", \"CODMES\", \"ATTRITION\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definir los DataFrames con las variables y el del Target\n",
    "X = df_train_clientes[predictores]\n",
    "y = df_train_clientes[\"ATTRITION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importar el métofo train_test_split del sub-módulo model_selection de Scikit-learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selección de muestra de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_fillna = X_train.copy()\n",
    "X_train_fillna[\"EDAD\"].fillna(value=X_train_fillna[\"EDAD\"].mean(), inplace=True)\n",
    "X_train_fillna[\"ANTIGUEDAD\"].fillna(value=X_train_fillna[\"ANTIGUEDAD\"].mean(), inplace=True)\n",
    "X_val_fillna = X_val.copy()\n",
    "X_val_fillna[\"EDAD\"].fillna(value=X_train_fillna[\"EDAD\"].mean(), inplace=True)\n",
    "X_val_fillna[\"ANTIGUEDAD\"].fillna(value=X_train_fillna[\"ANTIGUEDAD\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeclf = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "treeclf.fit(X_train_fillna, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#graph = Source( export_graphviz(treeclf, out_file=None, feature_names=predictores, filled=True))\n",
    "#SVG(graph.pipe(format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from IPython.display import display                               \n",
    "from ipywidgets import interactive\n",
    "\n",
    "def plot_tree(crit, split, depth, min_split, min_leaf=0.2):\n",
    "    estimator = DecisionTreeClassifier(random_state = 0 \n",
    "          , criterion = crit\n",
    "          , splitter = split\n",
    "          , max_depth = depth\n",
    "          , min_samples_split=min_split\n",
    "          , min_samples_leaf=min_leaf)\n",
    "    estimator.fit(X_train_fillna, y_train)\n",
    "    graph = Source(export_graphviz(estimator\n",
    "          , out_file=None\n",
    "          , feature_names=predictores\n",
    "          , class_names=['0', '1', '2']\n",
    "          , filled = True))\n",
    "\n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"inter=interactive(plot_tree \n",
    "   , crit = [\"gini\", \"entropy\"]\n",
    "   , split = [\"best\", \"random\"]\n",
    "   , depth=[1,2,3,4]\n",
    "   , min_split=(0.1,1)\n",
    "   , min_leaf=(0.1,0.5))\n",
    "display(inter)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#003d5c>3. Comparando árboles de decisión con otros modelos</font>\n",
    "\n",
    "**Ventajas de los árboles de decisión:**\n",
    "\n",
    "- Puede usarse para regresión o clasificación\n",
    "- Se puede mostrar gráficamente\n",
    "- Altamente interpretable\n",
    "- Se puede especificar como una serie de reglas y una toma de decisiones humana más cercana a la de otros modelos\n",
    "- La predicción es rápida\n",
    "- Las variables no necesitan escala\n",
    "- Aprende automáticamente las interacciones de las variables\n",
    "- Tiende a ignorar variables irrelevantes\n",
    "- No paramétrico (superará a los modelos lineales si la relación entre las características y la respuesta es altamente no lineal)\n",
    "\n",
    "<img src=\"images/groot_advantages.gif\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Desventajas de los árboles de decisión:**\n",
    "\n",
    "- El rendimiento es (generalmente) no competitivo con los mejores métodos de aprendizaje supervisado\n",
    "- Puede sobredimensionar fácilmente los datos de entrenamiento (se requiere ajuste)\n",
    "- Pequeñas variaciones en los datos pueden resultar en un árbol completamente diferente (alta varianza)\n",
    "- La división binaria recursiva toma decisiones \"localmente óptimas\" que pueden no dar como resultado un árbol globalmente óptimo\n",
    "- No tiende a funcionar bien si las clases son altamente desequilibradas\n",
    "- No tiende a funcionar bien con conjuntos de datos muy pequeños\n",
    "\n",
    "<img src=\"images/groot_disadvantages.gif\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias**:\n",
    "- http://nbviewer.jupyter.org/github/albahnsen/PracticalMachineLearningClass/blob/master/notebooks/13_decision_trees.ipynb\n",
    "- https://lethalbrains.com/learn-ml-algorithms-by-coding-decision-trees-439ac503c9a4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
