{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Métodos Ensamblados - Bagging\n",
    "\n",
    "¿Por qué estamos aprendiendo sobre Ensamblados?\n",
    "\n",
    "- Método muy popular para mejorar el rendimiento predictivo de los modelos de aprendizaje automático\n",
    "- Proporciona una base para comprender modelos más sofisticados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos de la lección\n",
    "\n",
    "Los estudiantes podrán:\n",
    "\n",
    "- Definir el ensamblaje y sus requisitos\n",
    "- Identificar los dos métodos básicos de ensamblaje\n",
    "- Decidir si el ensamblaje manual es un enfoque útil para un problema dado\n",
    "- Explicar el bagging y cómo se puede aplicar a los árboles de decisión\n",
    "- Explicar cómo se calculan el error **\"out-of-bag\"** y las importancias de las  características de un bagged tree.\n",
    "- Explicar la diferencia entre bagged trees and Random Forests\n",
    "- Construir y ajustar un modelo de Random Forest en scikit-learn\n",
    "- Decidir si un Árbol de Decisión o un Random Forest es mejor modelo para un problema dado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje ensamblado es un tema ampliamente estudiado en la comunidad de Machine Learning. La idea principal detrás\n",
    "de la metodología de ensamblaje es combinar varios clasificadores base para tener un clasificador que supera a cada uno de ellos.\n",
    "\n",
    "Cuando tratamos de predecir la variable Target utilizando cualquier técnica de Machine Learning, las causas principales de la diferencia en los valores reales y de predicción son el ruido, la varianza y el sesgo. El aprendizaje ensamblado ayuda a reducir estos factores (excepto el ruido, que es un error irreductible).\n",
    "\n",
    "El principio central en el aprendizaje ensamblado es **inducir perturbaciones aleatorias en el procedimiento de aprendizaje para producir varios clasificadores base a partir de un solo conjunto de entrenamiento, y luego combinar los resultados de los clasificadores base para poder realizar la predicción final**. Para inducir las permutaciones aleatorias y, por lo tanto, crear los diferentes clasificadores base, se han propuesto varios métodos, en particular:\n",
    "* Bagging\n",
    "* Pasting\n",
    "* Random Forests \n",
    "* Random Patches  \n",
    "\n",
    "Finalmente, después de que los clasificadores base hayan sido entrenados, generalmente se combinan usando cualquiera de los siguientes métodos:\n",
    "* Mayoría de votos\n",
    "* Votación ponderada  \n",
    "* Stacking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay tres razones principales con respecto a por qué los métodos ensamblados funcionan mejor que los modelos individuales: estadística, computacional y representacional. \n",
    "\n",
    "Primero, desde un punto de vista estadístico, cuando el conjunto de aprendizaje es demasiado pequeño, un algoritmo puede encontrar varios modelos buenos dentro del espacio de búsqueda, que surgen para el mismo rendimiento en el conjunto de entrenamiento. Sin embargo, sin un conjunto de validación, existe el riesgo de elegir el modelo incorrecto. \n",
    "\n",
    "La segunda razón es computacional; en general, los algoritmos se basan en una optimización de búsqueda local y pueden quedar atrapados en un optima local. Entonces, un ensamblado puede resolver esto enfocando diferentes algoritmos a diferentes espacios en el conjunto de entrenamiento. \n",
    "\n",
    "La última razón es representacional. En la mayoría de los casos, para un conjunto de aprendizaje de tamaño finito, la verdadera función $ f $ no puede representarse con ninguno de los modelos candidatos. Al combinar varios modelos en un conjunto, es posible obtener un modelo con una mayor cobertura en el espacio de funciones representables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ch9_fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo\n",
    "\n",
    "Imaginemos que en lugar de construir un único modelo para resolver un problema de clasificación binario, creo **cinco modelos independientes**, y cada modelo predice de forma correcta aproximadamente el 70% de las veces. Si combina estos modelos en un \"ensamblado (conjunto)\" y utiliza su voto mayoritario como una predicción, ¿con qué frecuencia el ensamblado sería correcto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# establecer una semilla para la reproducibilidad\n",
    "np.random.seed(1234)\n",
    "\n",
    "# generar 1000 números random (entre 0 y 1) para cada modelo, representando 1000 observaciones\n",
    "mod1 = np.random.rand(1000)\n",
    "mod2 = np.random.rand(1000)\n",
    "mod3 = np.random.rand(1000)\n",
    "mod4 = np.random.rand(1000)\n",
    "mod5 = np.random.rand(1000)\n",
    "\n",
    "# each model independently predicts 1 (the \"correct response\") if random number was at least 0.3\n",
    "preds1 = np.where(mod1 > 0.3, 1, 0)\n",
    "preds2 = np.where(mod2 > 0.3, 1, 0)\n",
    "preds3 = np.where(mod3 > 0.3, 1, 0)\n",
    "preds4 = np.where(mod4 > 0.3, 1, 0)\n",
    "preds5 = np.where(mod5 > 0.3, 1, 0)\n",
    "\n",
    "# print the first 20 predictions from each model\n",
    "print(preds1[:20])\n",
    "print(preds2[:20])\n",
    "print(preds3[:20])\n",
    "print(preds4[:20])\n",
    "print(preds5[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the predictions and then round to 0 or 1\n",
    "ensemble_preds = np.round((preds1 + preds2 + preds3 + preds4 + preds5)/5.0).astype(int)\n",
    "\n",
    "# print the ensemble's first 20 predictions\n",
    "print(ensemble_preds[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué tan preciso era cada modelo individual?\n",
    "print(preds1.mean())\n",
    "print(preds2.mean())\n",
    "print(preds3.mean())\n",
    "print(preds4.mean())\n",
    "print(preds5.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cuál fue la precisión del ensamblado?\n",
    "print(ensemble_preds.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Nota: ** A medida que agrega más modelos al proceso de votación, la probabilidad de error disminuye, lo que se conoce como [Condorcet's Jury Theorem](http://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es Ensamblado?\n",
    "\n",
    "** El aprendizaje ensamblado (o \"conjunto\") ** es el proceso de combinar varios modelos predictivos para producir un modelo combinado que es más preciso que cualquier modelo individual.\n",
    "\n",
    "- ** Regresión: ** tomar el promedio de las predicciones\n",
    "- ** Clasificación: ** vote y use la predicción más común, o tome el promedio de las probabilidades pronosticadas\n",
    "\n",
    "Para que el conjunto funcione bien, los modelos deben tener las siguientes características:\n",
    "\n",
    "- ** Exacto: ** superan al modelo nulo\n",
    "- ** Independiente: ** sus predicciones se generan utilizando diferentes procesos\n",
    "\n",
    "** La gran idea: ** Si tiene una colección de modelos individualmente imperfectos (e independientes), los errores \"únicos\" hechos por cada modelo probablemente no serán hechos por el resto de los modelos, y por lo tanto el los errores se descartarán al promediar los modelos.\n",
    "\n",
    "Hay dos métodos básicos ** para el ensamblado: **\n",
    "\n",
    "- Ensamble manual de sus modelos individuales\n",
    "- Use un modelo que ensamble por usted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendimiento teórico de un ensamblado\n",
    "  Si suponemos que cada uno de los $ T $ clasificadores base tiene una probabilidad $ \\rho $ de predecir correctamente, la probabilidad de que un ensamblado tome la decisión correcta, asumiendo la independencia de los clasificadores, indicada por $ P_c $, se puede calcular utilizando la distribución binomial:\n",
    "\n",
    "$$P_c = \\sum_{j>T/2}^{T} {{T}\\choose{j}} \\rho^j(1-\\rho)^{T-j}.$$\n",
    "\n",
    "  Además, como se muestra, si $ T \\ge3 $ entonces:\n",
    "\n",
    "$$\n",
    "  \\lim_{T \\to  \\infty} P_c= \\begin{cases}\n",
    "            1  &\\mbox{if } \\rho>0.5 \\\\ \n",
    "            0  &\\mbox{if } \\rho<0.5 \\\\ \n",
    "            0.5  &\\mbox{if } \\rho=0.5 ,\n",
    "            \\end{cases}\n",
    "$$\n",
    "\tllevando a la conclusión de que\n",
    "$$\n",
    "  \\rho \\ge 0.5 \\quad \\text{and} \\quad T\\ge3 \\quad \\Rightarrow \\quad P_c\\ge \\rho.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Ensamblaje Manual\n",
    "\n",
    "¿Qué hace un buen modelo ensamblado manual?\n",
    "\n",
    "- Diferentes tipos de ** modelos **\n",
    "- Diferentes combinaciones de ** funciones **\n",
    "- Diferentes ** parámetros de ajuste **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning flowchart](https://raw.githubusercontent.com/justmarkham/DAT8/master/notebooks/images/crowdflower_ensembling.jpg)\n",
    "\n",
    "*Machine learning flowchart created by the [winner](https://github.com/ChenglongChen/Kaggle_CrowdFlower) of Kaggle's [CrowdFlower competition](https://www.kaggle.com/c/crowdflower-search-relevance)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Leer el dataset de entrenamiento\n",
    "import pandas as pd\n",
    "url = 'data/vehicles_train.csv'\n",
    "train = pd.read_csv(url)\n",
    "# Transformar la variable \"vtype\"\n",
    "train['vtype'] = train.vtype.map({'car':0, 'truck':1})\n",
    "# Leer el dataset de test\n",
    "url = 'data/vehicles_test.csv'\n",
    "test = pd.read_csv(url)\n",
    "# Transformar la variable \"vtype\"\n",
    "test['vtype'] = test.vtype.map({'car':0, 'truck':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar diferentes modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un diccionario, instanciar 4 técnicas de Aprendizaje Supervisado vistos hasta ahora, y que nos podrían ayudar a resolver este problema de regresión:\n",
    "- Regresión Lineal\n",
    "- Árbol de Regresión\n",
    "- Naive Bayes\n",
    "- KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "models = {'lr': LinearRegression(),\n",
    "          'dt': DecisionTreeRegressor(),\n",
    "          'nb': GaussianNB(),\n",
    "          'nn': KNeighborsRegressor()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los predictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictores = ['year', 'miles', 'doors', 'vtype']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los datasets de entrenamiento y prueba, y entrenar con cada técnica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entrenar todos los modelos\n",
    "X_train = train.loc[:, predictores]\n",
    "X_test = test.loc[:, predictores]\n",
    "y_train = train.price\n",
    "y_test = test.price\n",
    "\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debemos predecir con los datos de Prueba usando cada uno de los 4 modelos entrenados. Para ello definamos un DataFrame con los mismos índices que el DataFrame de Prueba y las columnas con los nombres de las técnicas usadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(index=test.index, columns=models.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando cada técnica, hay que predecir el precio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for model in models.keys():\n",
    "    y_pred[model] = models[model].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora evaluaremos el poder predictivo de cada técnica. Para ello importemos la métrica **mean_squared_error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando cada técnica, hay que evaluar el error obtenido por sus predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.keys():\n",
    "    print(model,np.sqrt(mean_squared_error(y_pred[model], y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar el error de la media de las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_pred.mean(axis=1), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Podemos utilizar la media ponderada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = (2, 4, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(np.average(y_pred, weights=weights, axis=1), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer combinaciones de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dErrors = {}\n",
    "lWeights = list(itertools.product(range(1, 5), repeat=4))\n",
    "for i, weights in enumerate(lWeights):\n",
    "    dErrors[i] = np.sqrt(mean_squared_error(np.average(y_pred, weights=weights, axis=1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minWeight = lWeights[min(dErrors, key=dErrors.get)]\n",
    "minWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(np.average(y_pred, weights=minWeight, axis=1), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación del ensamblaje manual con el enfoque de un solo modelo\n",
    "\n",
    "\n",
    "**Ventajas del ensamblaje manual:**\n",
    "\n",
    "- Incrementa la precisión predictiva\n",
    "- Fácil de comenzar\n",
    "\n",
    "** Desventajas del ensamblaje manual:**\n",
    "\n",
    "- Disminuye la interpretabilidad\n",
    "- Toma más tiempo para entrenar\n",
    "- Toma más tiempo para predecir\n",
    "- Más complejo para automatizar y mantener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Bagging\n",
    "\n",
    "La principal debilidad de los ** árboles de decisión ** es que no tienden a tener la mejor precisión predictiva. Esto se debe en parte a la **alta varianza**, lo que significa que diferentes divisiones en los datos de entrenamiento pueden conducir a árboles muy diferentes.\n",
    "\n",
    "**Bagging** es un procedimiento de propósito general que busca reducir la varianza de una técnica de Machine Learning, pero es particularmente útil para los árboles de decisión. Bagging es la abreviatura de **bootstrap aggregation**, que significa la agregación de muestras bootstrap.\n",
    "\n",
    "Pero ... ¿Qué es una **muestra bootstrap**? Una muestra aleatoria con reemplazo. Veamos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una semilla para que nos de los mismos valores\n",
    "np.random.seed(1)\n",
    "\n",
    "# Crear un array de 1 x 20\n",
    "nums = np.arange(1, 21)\n",
    "print(nums)\n",
    "\n",
    "# Obtener una muestra aleatoria de tamaño 20 con reemplazo\n",
    "print(np.random.choice(a=nums, size=20, replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo funciona el bagging (para árboles de decisión)? **\n",
    "\n",
    "1. Construir B árboles utilizando B muestras de arranque (bootstrap samples) de los datos de entrenamiento.\n",
    "2. Entrenar a cada árbol en su muestra de arranque (bootstrap sample) y haga predicciones.\n",
    "3. Combinar las predicciones:\n",
    "     - Promedio de las predicciones para ** árboles de regresión **\n",
    "     - Haz un voto para ** árboles de clasificación **\n",
    "\n",
    "Notas:\n",
    "\n",
    "- ** Cada muestra de arranque ** debe ser del mismo tamaño que el conjunto de entrenamiento original.\n",
    "- ** B ** debe ser un valor suficientemente grande para que el error parezca haberse \"estabilizado\".\n",
    "- Los árboles ** crecen en profundidad ** por lo que tienen alta varianza.\n",
    "\n",
    "Bagging aumenta la precisión predictiva al ** reducir la varianza **, similar a cómo la validación cruzada reduce la varianza asociada con la división entrenamiento / prueba (para estimar el error fuera de muestra) dividiendo muchas veces el promedio de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una semilla para que nos de los mismos valores\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = train.shape[0]\n",
    "n_B = 10\n",
    "\n",
    "# Crear 10 muestras bootstrap (seran usandos para elegir los registros del DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las filas para el primer árbol de decisión\n",
    "train.iloc[samples[0], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construir un árbol de decisión por cada muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instanciar el árbol de regresión\n",
    "treereg = DecisionTreeRegressor(max_depth=None, random_state=123)\n",
    "\n",
    "# Crear un DataFrame para almacenar las predicciones del precio por cada árbol\n",
    "y_pred = pd.DataFrame(index=test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# Entrenar un árbol por cada muestra bootstrap y hacer predicciones en el dataset de prueba\n",
    "for i, sample in enumerate(samples):\n",
    "    X_train = train.loc[sample, predictores]\n",
    "    y_train = train.loc[sample, 'price']\n",
    "    treereg.fit(X_train, y_train)\n",
    "    y_pred[i] = treereg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de cada Árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_B):\n",
    "    print(i, np.sqrt(mean_squared_error(y_pred[i], y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados del Ensamblado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de Decisión con Bagging en scikit-learn (with B=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definir los conjuntos de entrenamiento y test\n",
    "X_train = train.loc[:, predictores]\n",
    "y_train = train.loc[:, 'price']\n",
    "X_test = test.loc[:, predictores]\n",
    "y_test = test.loc[:, 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entrenar un BaggingRegressor usando DecisionTreeRegressor como \"estimador base\"\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagreg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=500, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar y predecir\n",
    "bagreg.fit(X_train, y_train)\n",
    "y_pred = bagreg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimando el error out-of-sample\n",
    "\n",
    "Para los modelos que usan bagging, el error out-of-sample se puede estimar sin usar la **división en entrenamiento/prueba** o la **validación cruzada**\n",
    "\n",
    "En promedio cada bagged tree usa aproximadamente **dos tercios** (~66%) de las observaciones. Para cada árbol, las **observaciones restantes** se llaman observaciones \"out-of-bag\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la primera muestra bootstrap\n",
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostar las observaciones \"en-bolsa\" por cada muestra\n",
    "porcentaje_average=0\n",
    "for sample in samples:\n",
    "    print(set(sample))\n",
    "    print((len(set(sample))*100.0)/n_samples)\n",
    "    porcentaje_average+=(len(set(sample))*100.0)/n_samples\n",
    "porcentaje_average/len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las observaciones \"fuera-de-bolsa\" por cada muestra\n",
    "for sample in samples:\n",
    "    print(sorted(set(range(n_samples)) - set(sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo calcular el error **\"out-of-bag\"**:\n",
    "\n",
    "1. Para cada observación en los datos de entrenamiento, prediga su valor de respuesta usando ** solo ** los árboles en los que esa observación fue un out-of-bag. Promedia esas predicciones (para la regresión) o toma un voto (para la clasificación).\n",
    "2. Compare todas las predicciones con los valores de respuesta reales para calcular el error out-of-bag error.\n",
    "\n",
    "Cuando B es suficientemente grande, el  **out-of-bag error**  es una estimación precisa de **out-of-sample error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el error \"fuera de bolsa\" (Coeficiente de Determinacion) para B=500\n",
    "bagreg.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.loc[~bagreg.estimators_samples_[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train['index'] = X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dRowPred = {}\n",
    "for i in range(X_train.shape[0]):\n",
    "    print(\"Registro #{0}\".format(i))\n",
    "    dRowPred[i] = []\n",
    "    for j in range(500):\n",
    "        if i in X_train.loc[~bagreg.estimators_samples_[j], 'index'].unique().tolist():\n",
    "            dRowPred[i].append(bagreg.estimators_[j].predict(X_train.loc[[i], predictores])[0])\n",
    "            #print(bagreg.estimators_[j].predict(X_train.loc[[i], predictores])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dRowAvgPred = []\n",
    "for i in dRowPred.keys():\n",
    "    dRowAvgPred.append({'index':i ,'pred': np.mean(dRowPred[i])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El coeficiente determina la calidad del modelo para replicar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_train, pd.DataFrame(dRowAvgPred)['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_train, pd.DataFrame(dRowAvgPred)['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimar la importancia de las características\n",
    "\n",
    "Usar Bagging aumenta **la precisión predictiva**, pero disminuye la **interpretabilidad del modelo** porque ya no es posible visualizar el árbol para comprender la importancia de cada característica.\n",
    "\n",
    "Sin embargo, aún podemos obtener un resumen general de las **importancias de la variables** de los modelos con bagging:\n",
    "\n",
    "- **Bagged regression trees:** calcula la cantidad total de **MSE** que se reduce debido a divisiones sobre una característica dada, promediada sobre todos los árboles.\n",
    "- **Bagged classification trees:** calcula la cantidad total del **índice de Gini** que disminuye debido a las divisiones sobre una característica determinada, promediada en todos los árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Random Forests\n",
    "\n",
    "Random Forests es una **ligera variación de árboles con bagging** que tiene un rendimiento aún mejor:\n",
    "\n",
    "- Exactamente como el bagging, creamos un conjunto de árboles de decisión utilizando muestras bootstrap del conjunto de entrenamiento.\n",
    "- Sin embargo, al construir cada árbol, cada vez que se considera una división, se elige una **muestra aleatoria de m características** como candidatos para dividir del **conjunto completo de características p**. La división solo permite usar **una de esas m características**.\n",
    "    - Se elige una nueva muestra aleatoria de características para ** cada árbol en cada división individual **.\n",
    "    - Para ** clasificación **, se elige m típicamente como la raíz cuadrada de p.\n",
    "    - Para ** regresión **, se elige m típicamente entre p/3 y p.\n",
    "\n",
    "¿Cuál es el motivo?\n",
    "- Supongamos que hay ** una característica muy fuerte ** en el conjunto de datos. Cuando se usan árboles con bagging, la mayoría de los árboles usarán esa característica como la división superior, lo que resulta en un conjunto de árboles similares **altamente correlacionados**.\n",
    "- Promediar cantidades altamente correlacionadas no reduce significativamente la varianza (que es el objetivo total del bagging).\n",
    "-  Al omitir aleatoriamente las características candidatas de cada división, **Random Forests \"decorrelaciona\" los árboles**, de modo que el proceso de promediado puede reducir la varianza del modelo resultante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Construir y afinar (tuning) Árboles de Decisiones y  Random Forests\n",
    "\n",
    "- Datos de clientes de un Banco (variables sociodemograficas, de comportamiento)\n",
    "- Cada observación representa un cliente\n",
    "- ** Objetivo: ** Predecir la aceptación de un crédito hipotecario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lectura del dataset\n",
    "df = pd.read_csv('data/DS_Credito Hipotecario.csv')\n",
    "\n",
    "df['SEXO'].fillna(df['SEXO'].mode()[0], inplace=True)\n",
    "df['FLAG_CASADO'].fillna(df['FLAG_CASADO'].mode()[0], inplace=True)\n",
    "df['NRO_DEPENDIENTES'].fillna(df['NRO_DEPENDIENTES'].mode()[0], inplace=True)\n",
    "df['FLAG_TRAB_INDEP'].fillna(df['FLAG_TRAB_INDEP'].mode()[0], inplace=True)\n",
    "df['INGRESOS_COSOLICITANTE'].fillna(df['INGRESOS_COSOLICITANTE'].mean(), inplace=True)\n",
    "df['MONTO_PRESTAMO_MILES'].fillna(df['MONTO_PRESTAMO_MILES'].mean(), inplace=True)\n",
    "df['PLAZO_PRESTAMO_MESES'].fillna(df['PLAZO_PRESTAMO_MESES'].mean(), inplace=True)\n",
    "df['FLAG_HISTORIAL_CREDITICIO'].fillna(df['FLAG_HISTORIAL_CREDITICIO'].mode()[0], inplace=True)\n",
    "\n",
    "df['SEXO'] = df['SEXO'].map({'Male': 0, 'Female': 1})\n",
    "df['FLAG_CASADO'] = df['FLAG_CASADO'].map({'No': 0, 'Yes': 1})\n",
    "df['EDUCACION'] = df['EDUCACION'].map({'Not Graduate': 0, 'Graduate': 1})\n",
    "df['FLAG_TRAB_INDEP'] = df['FLAG_TRAB_INDEP'].map({'No': 0, 'Yes': 1})\n",
    "df['FLAG_HISTORIAL_CREDITICIO'] = df['FLAG_HISTORIAL_CREDITICIO'].map({'Malo': 0, 'Bueno': 1})\n",
    "df = pd.concat([df, pd.get_dummies(df['TIPO_ZONA'], prefix = 'TIPO_ZONA', drop_first = True)], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['NRO_DEPENDIENTES'], prefix = 'NRO_DEPENDIENTES', drop_first = True)], axis=1)\n",
    "del df['TIPO_ZONA']\n",
    "del df['NRO_DEPENDIENTES']\n",
    "df['FLAG_CRED_HIPO'] = df['FLAG_CRED_HIPO'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definir X e Y\n",
    "predictores = ['SEXO', 'FLAG_CASADO', 'EDUCACION', 'FLAG_TRAB_INDEP', 'INGRESOS_SOLICITANTE', 'INGRESOS_COSOLICITANTE',\n",
    "                'MONTO_PRESTAMO_MILES', 'PLAZO_PRESTAMO_MESES','FLAG_HISTORIAL_CREDITICIO', 'TIPO_ZONA_Semiurban',\n",
    "                'TIPO_ZONA_Urban', 'NRO_DEPENDIENTES_1', 'NRO_DEPENDIENTES_2','NRO_DEPENDIENTES_3+']\n",
    "X = df[predictores]\n",
    "y = df.FLAG_CRED_HIPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predecir el Crédito Hipotecario con un árbol de decisión\n",
    "\n",
    "Encuentre el mejor ** max_depth ** para un árbol de decisión usando la validación cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Lista de valores para \"max_depth\"\n",
    "max_depth_range = range(1, 21)\n",
    "\n",
    "# Definir un lista para almacenar los promedios de los Auc por cada valor de \"max_depth\"\n",
    "auc_scores = []\n",
    "\n",
    "# Usa una validación cruzada de 10 folds con cada valor del \"max_depth\"\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "for depth in max_depth_range:\n",
    "    treecla = DecisionTreeClassifier(max_depth=depth, random_state=1)\n",
    "    auc_score = cross_val_score(treecla, X, y, cv=10, scoring='roc_auc')\n",
    "    auc_scores.append(np.mean(auc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar max_depth (eje x) versus AUC (eje y)\n",
    "plt.plot(max_depth_range, auc_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra el mejor AUC y el correspondiente \"max_depth\"\n",
    "sorted(zip(auc_scores, max_depth_range), reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth=3 fue el mejor, por lo que hay que entrenar un arbol usando ese valor de hiperparametro\n",
    "treecla = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "treecla.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la importancia de variables\n",
    "pd.DataFrame({'predictor':predictores, 'importancia':treecla.feature_importances_}).sort_values('importancia', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predecir el Crédito Hipotecario con Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "rfcla = RandomForestClassifier()\n",
    "rfcla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning n_estimators\n",
    "\n",
    "Un hiperparámetro importante es **n_estimators**, que es la cantidad de árboles que se deben entrenar. Debe ser un valor lo suficientemente grande como para que el error parezca haberse \"estabilizado\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Listar los valores a probar\n",
    "estimator_range = range(10, 310, 10)\n",
    "\n",
    "# Definir un lista para almacenar los promedios de los Auc por cada valor de \"max_depth\"\n",
    "AUC_scores = []\n",
    "\n",
    "# Usa una validación cruzada de 5 folds con cada valor del \"n_estimators\"\n",
    "for estimator in estimator_range:\n",
    "    rfcla = RandomForestClassifier(n_estimators=estimator, random_state=1, n_jobs=-1)\n",
    "    AUC_score = cross_val_score(rfcla, X, y, cv=5, scoring='roc_auc')\n",
    "    AUC_scores.append(np.mean(AUC_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar n_estimators (eje x) versus AUC (eje y)\n",
    "plt.plot(estimator_range, AUC_scores)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(AUC_scores, estimator_range), reverse=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_features\n",
    "\n",
    "El otro parámetro de ajuste importante es ** max_features **, que es el número de características que se deben considerar en cada división."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Listar los valores para \"max_features\"\n",
    "feature_range = range(1, len(predictores)+1)\n",
    "\n",
    "# Definir un lista para almacenar los promedios de los Auc por cada valor de \"max_features\"\n",
    "AUC_scores = []\n",
    "\n",
    "# Use una validación cruzada de 10 folds para cada valor de \"max_features\"\n",
    "for feature in feature_range:\n",
    "    rfdec = RandomForestClassifier(n_estimators=150, max_features=feature, random_state=1, n_jobs=-1)\n",
    "    AUC_score = cross_val_score(rfdec, X, y, cv=10, scoring='roc_auc')\n",
    "    AUC_scores.append(np.mean(AUC_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar max_features (eje x) versus AUC (eje y)\n",
    "plt.plot(feature_range, AUC_scores)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el mejor AUC y su correpondiente \"max_features\"\n",
    "sorted(zip(AUC_scores, feature_range), reverse=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustando un Random Forest con los mejores parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# max_features=6 is best and n_estimators=150 is sufficiently large\n",
    "rfreg = RandomForestRegressor(n_estimators=60, max_features=6, oob_score=True, random_state=1)\n",
    "rfreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg.predict(X[5:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute feature importances\n",
    "pd.DataFrame({'feature':predictores, 'importance':rfreg.feature_importances_}).sort_values('importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the out-of-bag R-squared score\n",
    "rfreg.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduciendo X a sus características más importantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar las dimensiones de X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer un umbral para qué características incluir\n",
    "print(rfreg.transform(X, threshold=0.1).shape)\n",
    "print(rfreg.transform(X, threshold='mean').shape)\n",
    "print(rfreg.transform(X, threshold='median').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new feature matrix that only includes important features\n",
    "X_important = rfreg.transform(X, threshold='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the RMSE for a Random Forest that only includes important features\n",
    "rfreg = RandomForestRegressor(n_estimators=150, max_features=3, random_state=1)\n",
    "scores = cross_val_score(rfreg, X_important, y, cv=10, scoring='mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando Random Forests con Árboles de Decisiones\n",
    "\n",
    "**Ventajas de Random Forests:**\n",
    "\n",
    "- El rendimiento es competitivo con los mejores métodos de aprendizaje supervisado\n",
    "- Proporciona una estimación más confiable de la importancia de las características (features)\n",
    "- Le permite estimar el error fuera de muestra sin usar entrenamiento / prueba dividida o validación cruzada\n",
    "\n",
    "**Desventajas de Random Forests:**\n",
    "\n",
    "- Menos interpretable\n",
    "- Más lento para entrenar\n",
    "- Más lento para predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning flowchart](https://raw.githubusercontent.com/justmarkham/DAT8/master/notebooks/images/driver_ensembling.png)\n",
    "\n",
    "*Machine learning flowchart created by the [second place finisher](http://blog.kaggle.com/2015/04/20/axa-winners-interview-learning-telematic-fingerprints-from-gps-data/) of Kaggle's [Driver Telematics competition](https://www.kaggle.com/c/axa-driver-telematics-analysis)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
