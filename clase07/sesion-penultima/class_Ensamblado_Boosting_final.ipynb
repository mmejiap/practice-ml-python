{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#003d5c>Boosting</font>\n",
    "**Boosting** es una técnica de ensamblado donde los predictores no se construyen de forma independiente, sino de forma **secuencial**.\n",
    "\n",
    "Esta técnica emplea la lógica donde **los predictores posteriores aprenden de los errores de los predictores previos**. Por lo tanto, las observaciones tienen una probabilidad desigual de aparecer en los modelos posteriores y las que tienen el error más alto aparecen más. (Por lo tanto, **las observaciones no se eligen según el proceso de arranque, sino según el error**).\n",
    "\n",
    "<img src=\"images/boosting.png\" width=\"600\">\n",
    "\n",
    "Los predictores se pueden elegir de una gama de modelos como árboles de decisión. Debido a que los nuevos predictores están aprendiendo de los errores cometidos por los predictores previos, se requieren menos tiempo o iteraciones para alcanzar las predicciones reales. \n",
    "\n",
    "Sin embargo tenemos que elegir cuidadosamente los criterios de detención o podríamos obtener un ajuste excesivo en los datos de entrenamiento (u overfitting). **Gradient Boosting** es un ejemplo de algoritmo del tipo Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>Intuición sobre los modelos Boosting</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos con un ejemplo simple. Queremos predecir la edad de una persona en función de si juegan videojuegos, disfrutan de la jardinería y si prefieren vestir sombreros. Nuestro objetivo es minimizar el error cuadrático. Tenemos estos nueve registros de entrenamiento para construir nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv(\"data/boosting_dataset.csv\")\n",
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictores_base = [\"LikesGardening\", \"PlaysVideoGames\", \"LikesHats\"]\n",
    "for col in predictores_base:\n",
    "    df_base[col] = df_base[col].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitivamente, podríamos esperar que:\n",
    "- Las personas a las que les gustan la jardinería son probablemente mayores.\n",
    "- Las personas a las que les gustan los videojuegos son probablemente más jóvenes.\n",
    "- La preferencia de usar sombrero es probablemente solo ruido aleatorio.\n",
    "\n",
    "Podemos hacer una inspección rápida y profunda de los datos para verificar estas suposiciones:\n",
    "\n",
    "|Variable|Falso|Verdadero|\n",
    "|--------|-|-|\n",
    "|LikesGardening|{13, 14, 15, 35}|{25, 49, 68, 71, 73}|\n",
    "|PlaysVideoGames|{49, 71, 73}|{13, 14, 15, 25, 35, 68}|\n",
    "|LikesHats|{14, 15, 49, 71}|{13, 25, 35, 68, 73}|\n",
    "\n",
    "Ahora modelemos los datos con un árbol de regresión. Para comenzar, necesitaremos que los nodos terminales tengan al menos tres instancias. Con esto en mente, el árbol de regresión hará su primera y última división en LikesGardening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtree = DecisionTreeRegressor(min_samples_leaf=3)\n",
    "dtree.fit(df_base[predictores_base], df_base[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from graphviz import Source\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import SVG\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "graph = Source(export_graphviz(dtree, out_file=None, feature_names=predictores_base, filled=True))\n",
    "SVG(graph.pipe(format='svg'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/blog_gb_tree1_3.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es bueno, pero le falta información valiosa de la característica LikesVideoGames. Intentemos dejar que los nodos terminales tengan 2 muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree2 = DecisionTreeRegressor(min_samples_leaf=2)\n",
    "dtree2.fit(df_base[predictores_base], df_base[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "graph = Source(export_graphviz(dtree2, out_file=None, feature_names=predictores_base, filled=True))\n",
    "SVG(graph.pipe(format='svg'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/gb_tree1B_4.png\" width=\"800\">\n",
    "\n",
    "Esta vez utilizamos información de PlaysVideoGames, pero también recogemos información de LikesHats, una buena indicación de que estamos sobreajustados y de que nuestro árbol está dividiendo el ruido aleatorio.\n",
    "\n",
    "Supongamos que medimos los errores de entrenamiento de nuestro primer árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base[\"Tree1_Prediction\"] = dtree.predict(df_base[predictores_base])\n",
    "df_base[\"Tree1_Residual\"] = df_base.apply(lambda row: row[\"Age\"] - row[\"Tree1_Prediction\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos construir un segundo árbol de regresión en base a los residuos del primer árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustamos con el primer arbol que NO consideraba la division por LikesHats\n",
    "dtree2 = DecisionTreeRegressor(min_samples_leaf=3)\n",
    "dtree2.fit(df_base[predictores_base], df_base[\"Tree1_Residual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "graph = Source(export_graphviz(dtree2, out_file=None, feature_names=predictores_base, filled=True))\n",
    "SVG(graph.pipe(format='svg'))\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/blog_gb_tree2_3.png\" width=\"400\">\n",
    "\n",
    "Tenga en cuenta que este árbol no incluye LikesHats, aunque nuestro árbol de regresión sobreajustado sí lo hizo. La razón es porque este árbol de regresión puede considerar LikesHats y PlaysVideoGames con respecto a todas las instancias de entrenamiento, contrariamente a nuestro árbol de regresión sobreajustado que solo consideró cada característica dentro de una pequeña región del espacio de entrada, permitiendo ruido aleatorio para seleccionar LikesHats como una característica de división.\n",
    "\n",
    "Ahora podemos mejorar las predicciones de nuestro primer árbol agregando las predicciones de \"corrección de errores\" de este árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base[\"Tree2_Residual_Prediction\"] = dtree2.predict(df_base[predictores_base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df_base[\"Tree2_Prediction\"]\n",
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base[\"Combined_Prediction\"] = df_base.apply(lambda row: row[\"Tree1_Prediction\"] + row[\"Tree2_Residual_Prediction\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base[\"Final_Residual\"] = df_base.apply(lambda row: row[\"Age\"] - row[\"Combined_Prediction\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tree1 SSE: {0}\".format(int(df_base[\"Tree1_Residual\"].apply(lambda x: x**2).sum())))\n",
    "print(\"Tree Combined 1 SSE: {0}\".format(int(df_base[\"Final_Residual\"].apply(lambda x: x**2).sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree3 = DecisionTreeRegressor(min_samples_leaf=3)\n",
    "dtree3.fit(df_base[predictores_base], df_base[\"Final_Residual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "graph = Source(export_graphviz(dtree3, out_file=None, feature_names=predictores_base, filled=True))\n",
    "SVG(graph.pipe(format='svg'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base[\"Tree3_Prediction\"] = dtree3.predict(df_base[predictores_base])\n",
    "df_base[\"Combined_2_Prediction\"] = df_base.apply(lambda row: row[\"Combined_Prediction\"] + row[\"Tree3_Prediction\"], axis=1)\n",
    "df_base[\"Final_2_Residual\"] = df_base.apply(lambda row: row[\"Age\"] - row[\"Combined_2_Prediction\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tree Combined 2 SSE: {0}\".format(int(df_base[\"Final_2_Residual\"].apply(lambda x: x**2).sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primera Intuición\n",
    "\n",
    "Inspirados por la idea anterior, creamos nuestra primera intuición sobre el Gradient Boosting. En pseudocódigo:\n",
    "\n",
    "- Entrenar un modelo en base a los datos: F_1(x) = y\n",
    "- Entrenar un modelo en base a los residuos: h_1(x) = y - F_1(x)\n",
    "- Crear un nuevo modelo: F_2(x) = F_1(x) + h_1(x)\n",
    "\n",
    "No es difícil ver cómo podemos generalizar esta idea insertando más modelos que corrijan los errores del modelo anterior.\n",
    "Es decir:\n",
    "\n",
    "$$ F(x) = F_{1}(x) \\rightarrow F_{2}(x) = F_{1}(x) + h_{1}(x) ... \\rightarrow F_{M}(x) = F_{M-1}(x) + h_{M-1}(x)$$\n",
    "\n",
    "donde F_1(x) es el modelo inicial ajustado a **y**\n",
    "\n",
    "Dado que inicializamos todo el procedimiento ajustando F_1 (x), nuestra tarea en cada paso es encontrar:\n",
    "$$h_{m}(x) = y - F_{m} (x)$$\n",
    "\n",
    "Pausemos un poco y notemos que h_m es sólo un modelo. No necesariamente tiene que ser un modelo basado en árbol. Este es una de las grandes ventajas del gradient boosting debido a que realmente es solo un marco para mejorar iterativamente cualquier weak model. En la práctica, sin embargo, h_m es casi siempre un modelo basado en árboles, por lo que está bien interpretar h_m como un árbol de regresión como el de nuestro ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segunda Intuición\n",
    "\n",
    "Ahora modificaremos nuestro modelo para que se ajuste a la mayoría de las implementaciones de Gradient Boosting: inicializaremos el modelo con un único valor de predicción. Dado que nuestra tarea (por ahora) es minimizar el error cuadrático, inicializaremos **F** con la media de los valores Target de entrenamiento.\n",
    "\n",
    "$$F_{0}(x) = \\dfrac{1}{n}\\sum_{i=1}^{n}y_{i}$$\n",
    "\n",
    "Entonces podemos definir cada F_m subsiguiente recursivamente, como antes:\n",
    "\n",
    "$$F_{m+1}(x) = F_{m}(x) + h_{m}(x) = y, m\\geq0$$\n",
    "\n",
    "donde h_m proviene de una clase de modelos bases **H** (por ejemplo, árboles de regresión).\n",
    "\n",
    "En este punto, es posible que nos preguntemos cómo seleccionar el mejor valor para el hiperparámetro m del modelo. En otras palabras, ¿cuántas veces debemos iterar el procedimiento de corrección residual hasta que decidamos un modelo final, F? Esto se responde mejor al probar diferentes valores de m mediante validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tercera Intuición\n",
    "Hasta ahora hemos estado construyendo un modelo que minimiza el error cuadrático, pero ¿qué pasaría si quisiéramos minimizar el error absoluto?\n",
    "Podríamos modificar nuestro modelo base (árbol de regresión) para minimizar el error absoluto, pero esto tiene un par de inconvenientes.\n",
    "\n",
    "- Dependiendo del tamaño de los datos, esto podría ser muy costoso desde el punto de vista computacional. (Cada división considerada necesitaría buscar una mediana).\n",
    "- Arruina nuestro sistema de \"plug-in\". Solo podríamos conectar modelos base que soporten la función objetiva que queremos usar.\n",
    "\n",
    "Sin embargo, vamos a hacer algo mucho más rápido. Recordemos nuestro problema de ejemplo. Para determinar F_0, comenzamos eligiendo un minimizador de error absoluto. Esta será la mediana(y) = 35. Ahora podemos medir los residuos, y - F_0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base1 = pd.read_csv(\"data/boosting_dataset.csv\")\n",
    "df_base1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictores_base = [\"LikesGardening\", \"PlaysVideoGames\", \"LikesHats\"]\n",
    "for col in predictores_base:\n",
    "    df_base1[col] = df_base1[col].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base1[\"F0\"] = df_base1[\"Age\"].median()\n",
    "df_base1[\"Residual0\"] = df_base1.apply(lambda row: row[\"Age\"] - row[\"F0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere la primera y cuarta instancia de entrenamiento. Tienen residuos F0 de -22 y -10 respectivamente. Ahora supongamos que podemos hacer que cada predicción esté 1 unidad más cerca de su objetivo. Las reducciones respectivas del error cuadrático serían 43 y 19, mientras que las respectivas reducciones de error absoluto serían 1 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SSE: {0}\".format(int(df_base1[\"Residual0\"].apply(lambda x: x**2).sum())))\n",
    "print(\"SAE: {0}\".format(int(df_base1[\"Residual0\"].apply(lambda x: abs(x)).sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base1.loc[0, \"F0\"] = 34\n",
    "df_base1[\"Residual0\"] = df_base1.apply(lambda row: row[\"Age\"] - row[\"F0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SSE: {0}\".format(int(df_base1[\"Residual0\"].apply(lambda x: x**2).sum())))\n",
    "print(\"SAE: {0}\".format(int(df_base1[\"Residual0\"].apply(lambda x: abs(x)).sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base1.loc[3, \"F0\"] = 34\n",
    "df_base1[\"Residual0\"] = df_base1.apply(lambda row: row[\"Age\"] - row[\"F0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SSE: {0}\".format(int(df_base1[\"Residual0\"].apply(lambda x: x**2).sum())))\n",
    "print(\"SAE: {0}\".format(int(df_base1[\"Residual0\"].apply(lambda x: abs(x)).sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, un árbol de regresión, que por defecto minimiza el error cuadráctico, se enfocará fuertemente en reducir el residuo de la primera muestra de entrenamiento. Pero si queremos minimizar el error absoluto, mover cada predicción de una unidad más cerca del objetivo produce una reducción igual en la función de costo. Con esto en mente, supongamos que **en lugar de entrenar h_0 en base a los residuos de F_0, entrenamos h_0 en base a la gradiente de la función de costo, L(y, F_0 (x)) con respecto a los valores de predicción producidos por F_0 (x).**\n",
    "\n",
    "Esencialmente, entrenaremos h_0 en base a la reducción de costos para cada muestra si el valor predicho se convirtiera en una unidad más cercana al valor observado. En el caso de error absoluto, h_m simplemente considerará el signo de cada F_m residual (muy diferente al error cuadráctico que consideraría la magnitud de cada residuo).\n",
    "\n",
    "Después de agrupar las muestras h_m en hojas, se puede calcular un gradiente promedio y luego escalarlo por algún factor, **\\gamma**, de modo que **F_m + \\gamma*h_m** minimice la función de pérdida para las muestras en cada hoja. (Tenga en cuenta que en la práctica, se elige un factor diferente para cada hoja)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descenso de Gradiente\n",
    "\n",
    "Vamos a formalizar esta idea usando el concepto de Descenso de Gradiente. Considere una función diferenciable que queremos minimizar. Por ejemplo:\n",
    "\n",
    "$$L(x_{1}, x{2}) = \\frac{1}{2}(x_{1} - 15)^{2} + \\frac{1}{2}(x_{2} - 25)^{2}$$\n",
    "\n",
    "El objetivo aquí es encontrar el par (x_1, x_2) que minimice L. Tenga en cuenta que puedes interpretar esta función al calcular el error cuadrado para dos puntos de datos, 15 y 25 dados dos valores de predicción, x_1 y x_2. Aunque podemos minimizar esta función directamente, el descenso de gradiente nos permitirá minimizar las funciones de pérdida más complicadas que no podemos minimizar directamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasos de inicialización:\n",
    "- Número de pasos de iteración: $$M = 100$$\n",
    "- Punto de inicio: $$s^{0} = (0, 0)$$\n",
    "- Tamaño de paso: $$\\gamma = 0.1$$\n",
    "\n",
    "Por cada iteración m=1 hasta M:\n",
    "- Calcule el gradiente de L en el punto s^(m-1)\n",
    "- \"Paso\" en la dirección del mayor descenso (el gradiente negativo) con el tamaño de paso \\gamma. Es decir: $$s^{m} =  s^{m-1}-\\gamma\\nabla L(s^{(m-1)})$$\n",
    "\n",
    "Si \\gamma es pequeño y M es suficientemente grande, s^{M} será la ubicación del valor mínimo de L.\n",
    "\n",
    "Para más detalle sobre el descenso de Gradiente, revisar el siguiente [link](https://en.wikipedia.org/wiki/Gradient_descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descenso de Gradiente en Gradient Boosting\n",
    "\n",
    "Ahora podemos usar el descenso de gradiente para nuestro modelo. La función objetivo que queremos minimizar es L. Nuestro punto de partida es F_0 (x). Para la iteración m = 1, calculamos el gradiente de L con respecto a F_0 (x).\n",
    "\n",
    "Luego ajustamos un modelo a los componentes de la gradiente. El resultado es F_1. Entonces podemos repetir el proceso hasta que tengamos F_M. Modifiquemos nuestro algoritmo de aumento de gradiente para que funcione con cualquier función de pérdida diferenciable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base2 = pd.read_csv(\"data/boosting_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictores_base = [\"LikesGardening\", \"PlaysVideoGames\", \"LikesHats\"]\n",
    "for col in predictores_base:\n",
    "    df_base2[col] = df_base2[col].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base2[\"F0\"] = df_base2[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base2[\"PseudoResidual0\"] = df_base2.apply(lambda row: row[\"Age\"] - row[\"F0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtree0 = DecisionTreeRegressor(min_samples_leaf=3)\n",
    "dtree0.fit(df_base2[predictores_base], df_base2[\"PseudoResidual0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "graph = Source(export_graphviz(dtree0, out_file=None, feature_names=predictores_base, filled=True))\n",
    "SVG(graph.pipe(format='svg'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base2[\"h0\"] = dtree0.predict(df_base2[predictores_base])\n",
    "df_base2[\"gamma0\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base2[\"F1\"] = df_base2.apply(lambda row: row[\"F0\"] + row[\"gamma0\"]*row[\"h0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base2[\"PseudoResidual1\"] = df_base2.apply(lambda row: row[\"Age\"] - row[\"F1\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtree1 = DecisionTreeRegressor(min_samples_leaf=3)\n",
    "dtree1.fit(df_base2[predictores_base], df_base2[\"PseudoResidual1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "graph = Source(export_graphviz(dtree1, out_file=None, feature_names=predictores_base, filled=True))\n",
    "SVG(graph.pipe(format='svg'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base2[\"h1\"] = dtree1.predict(df_base2[predictores_base])\n",
    "df_base2[\"gamma1\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base2[\"F2\"] = df_base2.apply(lambda row: row[\"F1\"] + row[\"gamma1\"]*row[\"h1\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conocer más a detalle sobre los algoritmos del tipo Boosting revisar las siguientes referencias:\n",
    "- [Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)\n",
    "- [XGBoost](http://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf)\n",
    "- [LGBM](https://github.com/Microsoft/LightGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>Aplicar al Dataset De Attrition</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cargamos nuestra data de Attrition\n",
    "df_train_clientes = pd.read_excel('data/train_clientes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_clientes.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_clientes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seleccionamos las variables categóricas\n",
    "columns_cat = [\"RANG_INGRESO\", \"RANG_SDO_PASIVO_MENOS0\", \"RANG_NRO_PRODUCTOS_MENOS0\"]\n",
    "labelEncoders = {}\n",
    "\n",
    "# Hacemos el Label Encoding\n",
    "for col in columns_cat:\n",
    "    labelEncoders[col] = LabelEncoder()\n",
    "    df_train_clientes['{0}_ENC'.format(col)] = labelEncoders[col].fit_transform(df_train_clientes[col].fillna('na'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_clientes = pd.concat([df_train_clientes, pd.get_dummies(df_train_clientes['FLAG_LIMA_PROVINCIA'], prefix = 'FLAG_LIMA_PROVINCIA', drop_first = True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clientes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Eliminamos las variables del tipo object\n",
    "df_train_clientes.drop(axis=1, labels=[\"RANG_INGRESO\", \"RANG_SDO_PASIVO_MENOS0\", \"RANG_NRO_PRODUCTOS_MENOS0\", \"FLAG_LIMA_PROVINCIA\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_clientes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función para reducir la memoria que ocupa un DataFrame\n",
    "def optimizar(df):\n",
    "    float_cols = df.select_dtypes(include=['float'])\n",
    "    int_cols = df.select_dtypes(include=['integer'])\n",
    "\n",
    "    for var_f in float_cols.columns:\n",
    "        df[var_f] = pd.to_numeric(df[var_f], downcast='float')\n",
    "    for var_i in int_cols.columns:\n",
    "        df[var_i] = pd.to_numeric(df[var_i], downcast='integer')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizamos la memoria del DataFrame\n",
    "df_train_clientes = optimizar(df_train_clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definir los predictores (variables independientes)\n",
    "predictores = [c for c in df_train_clientes.columns if c not in [\"ID_CORRELATIVO\", \"CODMES\", \"ATTRITION\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definir los DataFrames con las variables y el del Target\n",
    "X = df_train_clientes[predictores]\n",
    "y = df_train_clientes[\"ATTRITION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de muestra de entrenamiento, prueba y validación\n",
    "<br><img src=\"images/split_data.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importar el método train_test_split del sub-módulo model_selection de Scikit-learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selección de muestra de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aquellos algoritmos que tienen problemas al tratar con missings, vamos a crear un dataframe imputándolos con la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_fillna = X_train.copy()\n",
    "X_train_fillna[\"EDAD\"].fillna(value=X_train_fillna[\"EDAD\"].mean(), inplace=True)\n",
    "X_train_fillna[\"ANTIGUEDAD\"].fillna(value=X_train_fillna[\"ANTIGUEDAD\"].mean(), inplace=True)\n",
    "X_val_fillna = X_val.copy()\n",
    "X_val_fillna[\"EDAD\"].fillna(value=X_train_fillna[\"EDAD\"].mean(), inplace=True)\n",
    "X_val_fillna[\"ANTIGUEDAD\"].fillna(value=X_train_fillna[\"ANTIGUEDAD\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_val_fillna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_fillna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>Instalación de librerías</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalemos las librerías que vamos a utilizar durante la clase:\n",
    "- **xgboost**: Librería con los métodos de Xtreme Gradient Boosting Model.\n",
    "- **lightgbm**: Librería con los métodos de Light Gradient Boosting Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. XGBoost:\n",
    "- Instalar [Git](https://git-scm.com/downloads).\n",
    "- Una vez instalado, abrir el programa de línea de comandos **Git Bash**.\n",
    "- Una vez abierto el programa, ubicarse en una carpeta donde se va a descargar la librería de **XGBoost** usando el comando: ***cd ruta_carpeta***\n",
    "- Una vez que nos encontremos en la carpeta, clonemos el repositorio de XGBoost de Github usando el siguiente comando: ***git clone https://github.com/dmlc/xgboost.git***\n",
    "- Ingresar al siguiente [link](http://www.picnet.com.au/blogs/guido/2016/09/22/xgboost-windows-x64-binaries-for-download/) y descargar el **.dll** más actual en la carpeta ***python-package/xgboost*** del directorio xgboost creado.\n",
    "- Ubicarse en la carpeta ***python-package*** del directorio xgboost creado y ejecutar el comando ***python setup.py install***\n",
    "\n",
    "### 2. LGBM:\n",
    "- Ejecutar la siguiente línea de comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>a) ExtraTrees (Bagging) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "extra_tree_model = ExtraTreesClassifier()\n",
    "extra_tree_model.fit(X_train_fillna, y_train)\n",
    "print('Tiempo de entrenamiento: {0:.2f} segundos.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extra_tree_y_pred = extra_tree_model.predict(X_val_fillna)\n",
    "extra_tree_y_prob_pred = extra_tree_model.predict_proba(X_val_fillna)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy de ExtraTree en el Dataset de Validación: {:.2f}'.format(accuracy_score(y_val, extra_tree_y_pred)))\n",
    "print('AUC de ExtraTree en el Dataset de Validación: {:.4f}'.format(roc_auc_score(y_val, extra_tree_y_prob_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_roc_auc = roc_auc_score(y_val, extra_tree_y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_val, extra_tree_y_prob_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr, tpr, label='ExtraTree (area = %0.4f)' % ex_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Ratio de Falsos Positivos')\n",
    "plt.ylabel('Ratio de Verdaderos Positivos')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotear la importancia de variables\n",
    "fig, ax = plt.subplots(figsize=(15, 20))\n",
    "df_importancia = pd.DataFrame({'variable': predictores, 'importancia':extra_tree_model.feature_importances_})\n",
    "df_importancia = df_importancia[[\"variable\", \"importancia\"]].sort_values(by=\"importancia\", ascending=True).reset_index(drop=True)\n",
    "df_importancia.plot(kind='barh', x='variable', y='importancia', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>b) AdaBoost (Boosting) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ab_model = AdaBoostClassifier()\n",
    "ab_model.fit(X_train_fillna, y_train)\n",
    "print('Tiempo de entrenamiento: {0:.2f} segundos.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ab_y_pred = ab_model.predict(X_val_fillna)\n",
    "ab_y_prob_pred = ab_model.predict_proba(X_val_fillna)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy de AdaBoost en el Dataset de Validación: {:.2f}'.format(accuracy_score(y_val, ab_y_pred)))\n",
    "print('AUC de AdaBoost en el Dataset de Validación: {:.4f}'.format(roc_auc_score(y_val, ab_y_prob_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_roc_auc = roc_auc_score(y_val, ab_y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_val, ab_y_prob_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr, tpr, label='AdaBoost (area = %0.4f)' % gb_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Ratio de Falsos Positivos')\n",
    "plt.ylabel('Ratio de Verdaderos Positivos')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotear la importancia de variables\n",
    "fig, ax = plt.subplots(figsize=(15, 20))\n",
    "df_importancia = pd.DataFrame({'variable': predictores, 'importancia':ab_model.feature_importances_})\n",
    "df_importancia = df_importancia[[\"variable\", \"importancia\"]].sort_values(by=\"importancia\", ascending=True).reset_index(drop=True)\n",
    "df_importancia.plot(kind='barh', x='variable', y='importancia', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=#003d5c>Ajuste o Tuning de Hiperparámetros</font>\n",
    "<br><img src=\"images/tuning.jpeg\" width=\"500\" height=\"20\">\n",
    "\n",
    "#### <font color=#003d5c>Diferencia entre Hiperparámetros y Parámetros</font>\n",
    "<br><img src=\"images/hyperparameter_concept.png\" width=\"500\" height=\"20\">\n",
    "\n",
    "- **Hiperparámetro:** Es lo que ajustamos para poder optimizar el rendimiento de nuestro modelo. Es como si giraramos (ajuste) las perillas de una Radio AM para obtener una señal clara (performance). Por ejemplo: El número de árboles y el número de variables para cada árbol en un Random Forest.\n",
    "\n",
    "- **Parámetro:** Es lo que se aprende durante la fase de entrenamiento. No pueden ser manipulados. Por ejemplo: la pendiente y el intercepto en una regresión. En un Random Forest los parámetros serían las variables y los umbrales utilizados para cada árbol.\n",
    "\n",
    "\n",
    "Scikit-Learn implementa un conjunto de hiperparámetros predeterminados razonables para todos los modelos, pero no se garantiza que sean óptimos para un problema. Los mejores hiperparámetros generalmente son imposibles de determinar con anticipación, y ajustar o hacer tuning de un modelo es donde el aprendizaje automático pasa de ser una ciencia a una ingeniería basada en prueba y error.\n",
    "\n",
    "#### <font color=#003d5c>¿Cuál es el enfoque en el Tunning?</font>\n",
    "<br><img src=\"images/Bias-Variance-Tradeoff.png\" width=\"500\" height=\"20\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ab_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 5000, num = 49)]\n",
    "learning_rate = [10 ** (-e) for e in range(1, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cuantos valores tengo de n_estimators: {0}\".format(len(n_estimators)))\n",
    "print(\"Cuantos valores tengo de learning_rate: {0}\".format(len(learning_rate)))\n",
    "print(\"Cuantos combinaciones tengo: {0}\".format(len(learning_rate) * len(n_estimators)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(n_estimators) * len(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Crear la grilla aleatoria\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate\n",
    "              }\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el proceso de Tuning, en cada iteración se debe escoger un conjunto diferente de Hiperparametros. En total en este caso existen 196 combinaciones, sin embargo el beneficio de la grilla aleatoria es que no necesitamos probar cada combinación, sino que se selecciona al azar para muestrear una amplia gama de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ab_b_model = AdaBoostClassifier()\n",
    "ab_t_model = RandomizedSearchCV(estimator = ab_b_model, param_distributions = random_grid, n_iter = 50, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "ab_t_model.fit(X_train_fillna, y_train)\n",
    "print('Tiempo de entrenamiento: {0:.2f} segundos.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ab_t_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ab_y_t_pred = ab_t_model.best_estimator_.predict(X_val_fillna)\n",
    "ab_y_t_prob_pred = ab_t_model.best_estimator_.predict_proba(X_val_fillna)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy de AdaBoost en el Dataset de Validación: {:.2f}'.format(accuracy_score(y_val, ab_y_t_pred)))\n",
    "print('AUC de AdaBoost en el Dataset de Validación: {:.4f}'.format(roc_auc_score(y_val, ab_y_t_prob_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ab_t_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ab_t_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_iter: Número de combinaciones de hiperparámetros a probar.\n",
    "- cv: Número de folds a usar para el cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda aleatoria nos permitió reducir el rango para cada hiperparámetro. Ahora que sabemos dónde concentrar nuestra búsqueda, podemos especificar explícitamente cada combinación de configuraciones para probar. Hacemos esto con GridSearchCV, un método que, en lugar de tomar muestras al azar de una distribución, evalúa todas las combinaciones que definimos. Para usar la búsqueda de la grilla, haremos otra grilla basada en los mejores valores proporcionados por la búsqueda aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = [4700, 4750]\n",
    "learning_rate = [0.1, 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la grilla aleatoria\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate\n",
    "              }\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ab_bg_model = AdaBoostClassifier()\n",
    "ab_tg_model = GridSearchCV(estimator = ab_bg_model, param_grid = param_grid, cv = 5, verbose=2, n_jobs = -1)\n",
    "ab_tg_model.fit(X_train_fillna, y_train)\n",
    "print('Tiempo de entrenamiento: {0:.2f} segundos.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ab_tg_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ab_y_tg_pred = ab_tg_model.best_estimator_.predict(X_val_fillna)\n",
    "ab_y_tg_prob_pred = ab_tg_model.best_estimator_.predict_proba(X_val_fillna)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy de AdaBoost en el Dataset de Validación: {:.2f}'.format(accuracy_score(y_val, ab_y_tg_pred)))\n",
    "print('AUC de AdaBoost en el Dataset de Validación: {:.4f}'.format(roc_auc_score(y_val, ab_y_tg_prob_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ab_tg_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ab_tg_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>b) XGBoost</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print('Tiempo de entrenamiento: {0:.2f} segundos.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_train = xgb.DMatrix(X_train[predictores], label=y_train)\n",
    "xgb_val = xgb.DMatrix(X_val[predictores], label=y_val)\n",
    "\n",
    "param = {}\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "watchlist = [(xgb_train, 'train'), (xgb_val, 'test')]\n",
    "num_boost_round = 400\n",
    "\n",
    "xgb_model = xgb.train(params=param, dtrain=xgb_train, num_boost_round=num_boost_round, evals=watchlist)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_y_pred = xgb_model.predict(X_val)\n",
    "xgb_y_prob_pred = xgb_model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy de XGBoost en el Dataset de Validación: {:.2f}'.format(accuracy_score(y_val, xgb_y_pred)))\n",
    "print('AUC de XGBoost en el Dataset de Validación: {:.4f}'.format(roc_auc_score(y_val, xgb_y_prob_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "xgb_ax = xgb.plot_importance(booster=xgb_model, ax=ax, importance_type=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_roc_auc = roc_auc_score(y_val, xgb_y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_val, xgb_y_prob_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr, tpr, label='XGBoost (area = %0.4f)' % gb_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Ratio de Falsos Positivos')\n",
    "plt.ylabel('Ratio de Verdaderos Positivos')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#003d5c>c) LGBM</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rounds = 500\n",
    "deep = 8\n",
    "eta = 0.05\n",
    "seed_val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"binary\"\n",
    "params['metric'] = 'auc'\n",
    "#params['num_class'] = 2\n",
    "params[\"max_depth\"] = deep\n",
    "params[\"min_data_in_leaf\"] = 20\n",
    "params[\"learning_rate\"] = eta\n",
    "params[\"bagging_fraction\"] = 0.7\n",
    "params[\"feature_fraction\"] = 0.7\n",
    "params[\"bagging_freq\"] = 5\n",
    "params[\"bagging_seed\"] = seed_val\n",
    "params[\"verbosity\"] = 0\n",
    "num_rounds = rounds\n",
    "evals_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgbm_val = lgb.Dataset(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_model = lgb.train(\n",
    "    params=params,\n",
    "    train_set=lgbm_train,\n",
    "    num_boost_round=num_rounds,\n",
    "    valid_sets=[lgbm_val],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=20,\n",
    "    evals_result=evals_result\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "lgb_ax = lgb.plot_importance(lgb_model, ax=ax, importance_type=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "lgbm_model = LGBMClassifier()\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "print('Tiempo de entrenamiento: {0:.2f} segundos.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_y_pred = lgbm_model.predict(X_val)\n",
    "lgbm_y_prob_pred = lgbm_model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy de LGBM en el Dataset de Validación: {:.2f}'.format(accuracy_score(y_val, lgbm_y_pred)))\n",
    "print('AUC de LGBM en el Dataset de Validación: {:.4f}'.format(roc_auc_score(y_val, lgbm_y_prob_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_roc_auc = roc_auc_score(y_val, lgbm_y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_val, lgbm_y_prob_pred)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr, tpr, label='LGBM (area = %0.4f)' % gb_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Ratio de Falsos Positivos')\n",
    "plt.ylabel('Ratio de Verdaderos Positivos')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "comet_tracking": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
